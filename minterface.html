<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="utf-8">

	<title>Multimodal interface for E-commerce | Pooja Dhaka</title>
	<link rel="stylesheet" type="text/css" href="blog-stylesheet.css">

	<!--fonts-->
	<link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800;900&display=swap"
		rel="stylesheet">
	<link href="https://fonts.googleapis.com/css2?family=Fira+Code&display=swap" rel="stylesheet">
	<link href="https://fonts.googleapis.com/css2?family=Lora:wght@400;500;600&display=swap" rel="stylesheet">
	<link href="https://fonts.googleapis.com/css2?family=Arima+Madurai&display=swap" rel="stylesheet">


	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta name="description" content="UX Researcher">
	<meta name="author" content="Pooja Dhaka">
	<link rel="shortcut icon" type="image/png" href="images/logo.svg" />


	<!-- Open graph protocol item-->
	<meta property="og:title" content="Multimodal interface for E-commerce">
	<meta property="og:description" content="Pooja Dhaka | UX Researcher">
	<meta property="og:image" content="">
	<meta property="og:url" content="">


	<!-- Twitter Open graph protocol item-->
	<meta name="twitter:title" content="Multimodal interface for E-commerce">
	<meta name="twitter:description" content="Pooja Dhaka | UX Researcher">
	<meta name="twitter:image" content="">
	<meta name="twitter:card" content="">

</head>


<body>
	<a href="index.html">
		<img class="top-nav" style="cursor: pointer" src="images/logo.svg">
	</a>

	<div class="div-container">
		<h1>Multimodal interface for E-commerce</h1>
		
	</div>


	<div class="div-container">

		<br><br>
		<h2>Overview</h2>
		<p>Flipkart was in the process of developing a voice-enabled interface to purchase grocery products along with the current text and graphic interface. This multimodal interface intends to allow users to search for grocery items, select, add, remove items in the cart, and finally order selected items.</p>
		<p>Prior studies conducted within Flipkart have suggested a preference to create a grocery list and shop via a multimodal interface. The multimodal interface should act as a guide and enabler to the moderately tech-savvy groups and convenience for the tech-savvy groups in India. Also, the multimodal modal interface provides the advantage of shopping in non-linear navigation and multi-language support.</p>
		<p class="italic-text p-small">To comply with my non-disclosure agreement, I have omitted and obfuscated confidential information in this case study. All information in this case study is my own and does not necessarily reflect the views of Flipkart.</p>
		
		<br>
		<h2>Research goal</h2>
		<p>I wanted to dive deeper into previous learnings by exploring and evaluating the multimodal interface for adapting to online grocery shopping.</p>
		<p>I conducted the study in 2 phases:</p>
		<ul>
			<li><strong>Phase 1</strong> was directed for concept testing of the initial prototype with a limited number of grocery shopping items in the app. The prototype could understand and respond to limited queries. This study’s insights provided direction to UX designers and voice designers for interface and conversational design, respectively.</li>
			<li><strong>Phase 2</strong> The app designs were changed based on phase 1 research insights and recommendations. Before launching the app to the user base, we evaluated the app.</li>
		</ul>
		<br>
		<h2>Phase 1</h2>
		<p>The research was conducted with the demo prototype. Before devising the research objectives, I collated the assumptions and questions from the team.</p>
		<p>Team: 3 Product managers, 2 Designers, and 3 Engineers.</p>
		<h3>Research Objectives:</h3>
		<p>I focused on understanding the shopping behavior using the multimodal interface with different cohort users and gather feedback around the multimodal interface. The objectives are:</p>
		<ul>
			<li>Understand current offline and online shopping (including Grocery buying) behavior of 3 cohorts:</li>
			<ul>
				<li>Assisted online shoppers</li>
				<li>Online shoppers, excluding groceries.</li>
				<li>Online grocery shoppers</li>
			</ul>
			<li>Understand the value perceived of voice interface by the above cohorts. Explore users’ expectations and aspirations from a multimodal interface for online grocery shopping.</li>
		</ul>
		<p class="italic-text p-small">*Initially, I took one more cohort of users (Assisted online grocery shoppers), but we could not find this cohort through an agency (or internal database), and I had to drop that cohort before initiating the field study.</p>
		<br>
		<h3>Participants’ recruitment</h3>
		<p>Participants were recruited from 3 cohorts: Online shoppers excluding grocery, Online grocery shoppers and Assisted online shoppers.</p>
		<p>Other criteria considered while recruiting the participants were: mix age group b/w 25–50 years, equal gender mix, a mix of occupations, and mix of online and offline shoppers from different apps and stores.</p>
		<p>These participants were recruited with the help of an agency. A recruiting screener was shared with the vendor agency, who can get a list of potential participants, sift through the responses, schedule appropriate participants, and manage their compensation for us.</p>
		<br>
		<h3>Research method</h3>
		<p>One-on-one interviews were conducted with the 3 cohorts of 24 participants in 3 cities — Bangalore, Hyderabad & Delhi. I interviewed the participants at their homes to observe the working of voice in their environment.</p>
	</div>

	<img class="img-compact" src="images/minterface/interviews.jpg">

	<div class="div-container">
		<p class="image-caption">1:1 interviews at participants’ homes</p>
		<p><strong>Task 1:</strong> Participants were shown the app to explore for 2–3 mins, and I asked questions on what they saw.</p>
		<p>Outcome:</p>
		<ul>
			<li>Awareness and understanding of the multimodal interface.</li>
			<li>Initial perceptions of the interface</li>
		</ul>
		<br>
		<p><strong>Task 2:</strong> Participants were asked to buy 6–8 grocery items using the app, and they have to go through the entire flow of shopping using the multimodal interface.</p>
		<p>Outcome:</p>
		<ul>
			<li>Comprehension and usefulness of the interface</li>
			<li>Issues faced during buying items (Shopping journey)</li>
			<li>Expectations of using the voice interface</li>
			<li>Preference of touch v/s voice</li>
		</ul>
		<br>
		<p><strong>Task 3:</strong> Participants were given some statements and asked to rate the experience based on their tasks on a scale of disagree to agree scale.</p>
		<p class="italic-text">The questionnaire consists of questions that probe seven different dimensions of the app (labeled categories): <strong>accuracy, concept, content, ease of use, the authenticity </strong>of the conversation, <strong>likability</strong>, and app conversation <strong>flow</strong>.</p>
		<br>
		<h2>App flow:</h2>
		<br><br>
	</div>

	<img class="img-center" src="images/minterface/app-flow.jpg">

	<div class="div-container">
		<br>
		<h3>Data analysis and synthesis</h3>
		<p>After a day’s sessions, we had a debriefing to reflect on the sessions. I analyzed the transcripts with the atlas.ti tool. I distilled insights and divided them into grocery shopping behaviour (deterrents and motivators of online grocery shopping), conversational insights, and interface insights, which provided direction to conversational and UX designers.</p>
		<p>Some of the actionable insights excerpted from the report with recommendations:</p>
		<h3>Interface insights</h3>
		<br>
		<p class="quote">Insight 1: Dialogues on the homepage portrayed false affordances. There was no touch affordance to view cart, modify items in the cart, and proceed to the next step.</p>
		<p><i>“Here it should be cart. In cart it will show all the items whatever I have added. There I tap and I see all the items I can buy or delete it. Here I don’t know where are the items gone."</i> - H6</p>
		<p><i>“It doesn’t take me. I don’t think it is taking me anywhere (tapped on dialogues)"</i> - B3</p>
		<p><i>“Don’t know why is this not working (tapped on dialogues)."</i> - D2</p>
		<br>
		<p><strong>Recommendation:</strong> <i>The option to choose between touch or voice affordances (Intermodal interface) needs to be intuitive. The interface should be self-explanatory, with the interface providing the necessary information (commands) for novice users to quickly understand to accomplish their tasks. Clear affordances need to be appropriately designed.</i></p>
		<br>
		<p class="quote">Insight 2: Helping commands displayed were not relevant to the context.</p>
		<p><i>“Commands should be written, what commands will be used and where. A tip should be there which command should be there. The command which she is able to understand."</i> - D4</p>
		<br>
		<p><strong>Recommendation:</strong> <i>Instead of general helping commands, the GUI should provide the user contextual helping commands.</i></p>
		<h3>Conversational insights</h3>
		<br>
		<p class="quote">Insight 3: Users expected the input and output to be conversational in nature, but this expectation was unmet. Users try to give commands based on the previously asked question, but the prototype cannot understand.</p>

		<p><i>Input: “I want to buy all products”</i>
		<br><i>Output: What would you like to buy?</i>
		<br><i>Input: “Just now which I added to cart”</i>
		<br><i>Result: None</i></p>

		<p><strong>Recommendation:</strong> <i>Conversational context must be preserved while taking input and output.</i></p>
		<br>
		<p class="quote">Insight 4: Formulation of voice command took time for users, and the listening time window closed before taking input, which frustrated the users.</p>
		<p><i>“It is not giving much time, within short time…hadbadi me batana hai ki kya karna hai. It has to listen to some duration. It is very impatient."</i> - D2</p>
		<p class="italic-text p-small">*The issue occurred with Bangalore participants and was resolved before heading to Hyderabad and Delhi. Engineers increased the input time.</p>
		<br>
		<p class="quote">Insight 5: Repetition of the same output commands/ errors annoyed the users as there is no direction to move forward in the conversation or fallback.</p>
		<p><strong>Recommendation:</strong> <i>When there are recognition rejects or speech timeouts, the app should provide details about the error and examples of what the users should say. With each subsequent error, more detail should be provided. Explicit in informing users what went wrong and what they can do in order to keep moving forward in conversation.</i></p>
		<br>
		<p class="quote">Insight 6: Listening mode was unresponsive during network connectivity issues, and users tend to repeat their queries in the same slot. As a result, no result was displayed, which puzzled the user.</p>
		<p><strong>Recommendation:</strong> <i>Feedback must be communicated in case of network connectivity issue.</i></p>
		<br>
		<h3>Impact</h3>
		<p>As a team, we brainstormed on the solutions based on the insights, incorporated design changes, and integrated them into the Flipkart app.</p>
		<br><br>
		<h2>Research Phase II</h2>
		<p>Before launching, I conducted a usability evaluation of the multimodal interface of the Flipkart app.</p>
		<h3>Research objectives:</h3>
		<br>
		<ul>
			<li>Evaluate and gather insights around the usability of multimodal interface designs for online grocery shopping with the three cohorts (Assisted shoppers, Online shoppers excluding grocery, and online shoppers, including grocery).</li>
			<li>The multimodal interface designs were evaluated based on the following:</li>
				<ol>
					<li>Discoverability and comprehension of voice feature on Supermart</li>
					<li>Conversational experience of the interface</li>
					<li>Successful completion of tasks using a voice interface.</li>
				</ol>
			<li>Understand users intent and mental model of using the multimodal interface for grocery shopping.</li>
			<li>Identify pain points in the app. Gather feedback from users on their motivations, barriers for adoption, and any other expectations.</li>
		</ul>
		<br>
		<h3>App Flow</h3>
		<br><br>
	</div>

	<img class="img-center" src="images/minterface/app-flow2.jpg">

	<div class="div-container">
		<p class="image-caption">Updated App Flow</p>
		<h3>Research method</h3>
		<p>I conducted one-on-one use case based evaluation with 18 participants in a lab setting from Bangalore, Delhi, and Mumbai.</p>
		<p>Each 1:1 session lasted 60–90 minutes and included a short briefing, an interview, and task performance with a test phone loaded with the prototype. During the test, participants were asked to use <strong>retrospective think-aloud</strong> protocol after they complete each task.</p>
	</div>

	<img class="img-center" src="images/minterface/participants.jpg">

	<div class="div-container">
		<p class="image-caption">Participants interacting with the multimodal interface. The video was recorded using ziggy and webcam.</p>
		<h3>Tasks:</h3>
		<br>
		<p><strong>1. Voice discovery and comprehension task:</strong></p>
		<p>Participants were asked to show how they buy grocery items on the app. If they notice the voice banner, I enquired about the same.</p>
		<p>Outcome:</p>
		<ul>
			<li>Voice discoverability</li>
			<li>Comprehension and understanding of the multimodal interface</li>
		</ul>
		<br>
		<p><strong>2. Grocery Shop along three sub-tasks:</strong></p>
		<ul>
			<li>Participants were asked to buy 6 grocery items for their house, and they have to shop the items using this (pointing on voice) on this app and observe how they would go about it.</li>
			<li>Participants were asked to buy 6 items more apart from what they had in the cart. They had to buy from 6 grocery categories cards), which they usually buy for their home (one item from each card). And observe how they would go about it.</li>
			<li>If participants didn't want any of the items in the cart, what will they do. And finally, if they had to order items, what will they do.</li>
		</ul>
		<p>Outcome:</p>
		<ul>
			<li>Discoverability and comprehension of contextual commands, help, bento, language, hamburger, commands on HP, edit on cart page.</li>
			<li>Error rates</li>
			<li>Comprehension of flow</li>
			<li>Touch vs speech input</li>
			<li>Delighters and concerns that users express unprompted are critical.</li>
			<li>Output prompts experience</li>
			<li>Unsupported intents/ utterances</li>
		</ul>
		<br>
		<h2>Data analysis and synthesis</h2>
		<p>The insights were distilled using atlas.ti software. The insights were syntheses in the report and divided into <strong>onboarding</strong> (of user on voice interface), <strong>input</strong> (voice input commands by users), <strong>output</strong> (voice output by app), <strong>Live feedback</strong> (Speech to text/ Transcription), <strong>Affordances</strong> (Helping text provided at the bottom of the screen at every page and text on the help page), <strong>Touch input</strong> and <strong>Bugs</strong>.</p>
		<br>
		<h3>Insights</h3>
		<p class="quote"><strong>Insight 1: Onboarding and voice button puzzled users</strong></p>
		<p>The homepage voice interaction starts with a welcome voice message and asks what they want. In response to the question, the user begins without tapping on the voice icon. As a result, there is no reaction from the app, which confuses the user.</p>
		<p>When they realize to tap, there is a lot of confusion around figuring out the voice button’s usage. Especially assisted shoppers had a hard time figuring out the voice icon functionality. It could be due to the cognitive load of all the elements on that page, and there is no focus on interaction.</p>
		<p class="italic-text"><strong>Recommendation:</strong>Every touch point in voice interaction journey has to be clearly communicated via visual & motion design. This will helps users understand to interact with voice.</p>
		<br>
	</div>

	<img class="img-compact" src="images/minterface/feedback-loop.jpg">

	<div class="div-container">
		<br><br>
		<p class="quote">Insight 2: Brands with categories were used as significant filtration criteria in a single query. But the system dropped the brand name or category and showed unexpected results. Filtration criteria by quantity, size, and color were also dropped, and with further retrials, the same results appeared.</p>
	</div>

	<img class="img-compact" src="images/minterface/queries.jpg">

	<div class="div-container">
		<p class="image-caption">Grocery queries by participants</p>
		<br><br>
		<p class="quote">Insight 3: Maintaining context backfired in some cases</p>
		<p>In some cases, the app remembered what the user said previously in the first input and maintained that context in the next input. Therefore, the results shown were a mix of the first and second input. It leads to the user retrying the input to see proper results.</p>
	</div>

	<img class="img-compact" src="images/minterface/testimonials.jpg">

	<div class="div-container">
		<h3>Impact:</h3>
		<p>The multimodal interface for grocery shopping was successfully launched in 5 cities, and the voice feature usage was increased by 3x from its initial launch.</p>
		<br>
		<h3>Next steps:</h3>
		<p>The learnings from the research studies were taken into account for the second category — Lifestyle. Another study was conducted to understand user behavior wrt to lifestyle shopping using a multimodal interface on Flipkart.</p>
	</div>






	<footer>
		<div class="div-container">
			<br><br><br>
			<hr> 
			<br><br><br>
		</div>

		<div class="div-container">
			<p class="next">Next</p>
			<br>
			<p><a href="supermart-home.html">Supermart Homepage</a></p>
			<p><a href="voice.html">Voice - Smart Devices</a></p>
			<p style="color: #999999"><a href="mailto:dhakapooja11@gmail.com">Get in touch</a> → dhakapooja11@gmail.com</style></p>
			<br>
		</div>
	</footer>

</body>

</html>